{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "#Params\n",
    "datasetPath = \"../datasets/\"\n",
    "dataPath = \"./dataTest/\"\n",
    "resultPath = \"./results3/\"\n",
    "#filenames = [\"BerkeleyC\",\"BerkeleyJ\",\"Dune\",\"HIPAcc\",\"HSMGP\",\"JavaGC\"]\n",
    "filenames = [\"Apache\",\"BerkeleyC\",\"BerkeleyJ\",\"Dune\",\"HIPAcc\"]\n",
    "perf=\"perf\"\n",
    "\n",
    "\n",
    "#Params for sensistivity\n",
    "NBINS = 10 # Number of vertical bins for threshold\n",
    "NSUBS = 10 # Number of training sets to average on\n",
    "srm = 1 # Minimum sampling size\n",
    "srM={}\n",
    "srs = {}\n",
    "for filename in filenames:\n",
    "    srM[filename] = int(subprocess.check_output(\"echo $(wc -l < \"+datasetPath+filename+\".csv)\", shell=True)) # Maximum sampling size\n",
    "    srs[filename] = srM[filename]//100 # Sampling step between two iterations\n",
    "    \n",
    "    \n",
    "#Params for Decision Tree\n",
    "#Default params\n",
    "classParamsDefault = {\n",
    "    \"criterion\":\"gini\",\n",
    "    \"splitter\":\"best\",\n",
    "    \"max_features\":None,\n",
    "    \"max_depth\":None,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":1,\n",
    "    \"min_weight_fraction_leaf\":0.,\n",
    "    \"max_leaf_nodes\":None,\n",
    "    \"class_weight\":None,\n",
    "    \"random_state\":None,\n",
    "    \"min_impurity_decrease\":1e-7,\n",
    "    \"presort\":False\n",
    "}\n",
    "regParamsDefault = {\n",
    "    \"criterion\":\"mse\",\n",
    "    \"splitter\":\"best\",\n",
    "    \"max_depth\":None,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":1,\n",
    "    \"min_weight_fraction_leaf\":0.,\n",
    "    \"max_features\":None,\n",
    "    \"random_state\":None,\n",
    "    \"max_leaf_nodes\":None,\n",
    "    \"min_impurity_decrease\":1e-7,\n",
    "    \"presort\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def newVersionFilename(path, filename):\n",
    "    # Get all the files in the {path} directory starting with {filename}\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f)) and f.startswith(filename+\"-\")]\n",
    "    files.sort(reverse=True)\n",
    "    # If no file yet\n",
    "    if len(files)==0:\n",
    "        return path+filename+\"-\"+str(1).zfill(4)\n",
    "    # Split the last one\n",
    "    splitted = files[0].split(\"-\")\n",
    "    # Get the last version\n",
    "    num = int(splitted[len(splitted)-2].split(\".\")[0])\n",
    "    # Return the full name with new version\n",
    "    return path+filename+\"-\"+str(num+1).zfill(4)\n",
    "\n",
    "\n",
    "def sensitivityClassification(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, classifParams, thresholds=False):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resClassification = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            #print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "\n",
    "            clean = d.drop([\"perf\"],axis=1,errors=\"ignore\")\n",
    "\n",
    "            c = tree.DecisionTreeClassifier(**classifParams)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for train_index, test_index in shuffle_split.split(clean,clean.label):\n",
    "                    c.fit(clean.drop([\"label\"],axis=1).iloc[train_index], clean.label.iloc[train_index])\n",
    "                    pred = c.predict(clean.drop([\"label\"],axis=1).iloc[test_index])\n",
    "                    \n",
    "                    dfTest = pd.DataFrame()\n",
    "                    dfTest[\"label\"] = clean.label.iloc[test_index]\n",
    "                    dfTest[\"pred\"] = pred\n",
    "\n",
    "                    TN += dfTest[(dfTest.label == 0) & (dfTest.pred == 0)].shape[0]\n",
    "                    TP += dfTest[(dfTest.label == 1) & (dfTest.pred == 1)].shape[0]\n",
    "                    FN += dfTest[(dfTest.label == 1) & (dfTest.pred == 0)].shape[0]\n",
    "                    FP += dfTest[(dfTest.label == 0) & (dfTest.pred == 1)].shape[0]\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "                break\n",
    "\n",
    "            resClassification[\"sr\"].append(sr)\n",
    "            resClassification[\"t\"].append(t)\n",
    "            resClassification[\"TN\"].append(TN/NSUBS)\n",
    "            resClassification[\"TP\"].append(TP/NSUBS)\n",
    "            resClassification[\"FN\"].append(FN/NSUBS)\n",
    "            resClassification[\"FP\"].append(FP/NSUBS)\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    \n",
    "    pd.DataFrame(resClassification).to_csv(newFilename+\"-classification.csv\", index=False)\n",
    "    \n",
    "    classifParamsUsed = dict(classifParams)\n",
    "    classifParamsUsed['file']=filename\n",
    "    classifParamsUsed['results']=newFilename+\"-classification.csv\"\n",
    "    \n",
    "    dfParamsUsed = pd.DataFrame.from_dict([classifParamsUsed])\n",
    "    \n",
    "    # If params list does not exists, create it\n",
    "    if not os.path.exists(dataPath+\"results-list.csv\"):\n",
    "        dfParamsUsed.to_csv(dataPath+\"results-list.csv\", index=False)\n",
    "    # If the list already exists, add the params used\n",
    "    else:\n",
    "        paramList = pd.read_csv(dataPath+\"results-list.csv\")\n",
    "        frames = [paramList, dfParamsUsed]\n",
    "        paramList = pd.concat(frames)\n",
    "        pd.DataFrame(paramList).to_csv(dataPath+\"results-list.csv\", index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityRegression(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, regParams, thresholds=False):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resRegression = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[],\"MSE\":[]}\n",
    "\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            #print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            \n",
    "            TN = TP = FN = FP = MSE = 0 # Counters for regression results\n",
    "\n",
    "            c = tree.DecisionTreeRegressor(**regParams)\n",
    "\n",
    "            for train_index, test_index in shuffle_split.split(d,d.label):\n",
    "                c.fit(d.drop([perf,\"label\"],axis=1).iloc[train_index], d[perf].iloc[train_index])\n",
    "                pred = c.predict(d.drop([perf,\"label\"],axis=1).iloc[test_index])\n",
    "                #print(list(pred))\n",
    "                #print(list(clean.label.iloc[test_index]))\n",
    "                #print()\n",
    "                dfTest = pd.DataFrame()\n",
    "                dfTest[perf] = d[perf].iloc[test_index]\n",
    "                dfTest[\"pred\"] = pred\n",
    "                dfTest[\"label\"] = d.label.iloc[test_index]\n",
    "                dfTest[\"label_pred\"] = 0\n",
    "                dfTest.loc[dfTest[\"pred\"] > t, \"label_pred\"] = 1\n",
    "                                 \n",
    "                MSE = mse(dfTest[perf],dfTest[\"pred\"])\n",
    "\n",
    "                TN += dfTest[(dfTest.label == 0) & (dfTest.label_pred == 0)].shape[0]\n",
    "                TP += dfTest[(dfTest.label == 1) & (dfTest.label_pred == 1)].shape[0]\n",
    "                FN += dfTest[(dfTest.label == 1) & (dfTest.label_pred == 0)].shape[0]\n",
    "                FP += dfTest[(dfTest.label == 0) & (dfTest.label_pred == 1)].shape[0]\n",
    "\n",
    "            resRegression[\"sr\"].append(sr)\n",
    "            resRegression[\"t\"].append(t)\n",
    "            resRegression[\"MSE\"].append(MSE/NSUBS)\n",
    "            resRegression[\"TN\"].append(TN/NSUBS)\n",
    "            resRegression[\"TP\"].append(TP/NSUBS)\n",
    "            resRegression[\"FN\"].append(FN/NSUBS)\n",
    "            resRegression[\"FP\"].append(FP/NSUBS)\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    pd.DataFrame(resRegression).to_csv(newFilename+\"-regression.csv\", index=False)\n",
    "    \n",
    "    regParamsUsed = dict(regParams)\n",
    "    regParamsUsed['file']=filename\n",
    "    regParamsUsed['results']=newFilename+\"-regression.csv\"\n",
    "    \n",
    "    dfParamsUsed = pd.DataFrame.from_dict([regParamsUsed])\n",
    "    \n",
    "    # If params list does not exists, create it\n",
    "    if not os.path.exists(dataPath+\"results-list.csv\"):\n",
    "        dfParamsUsed.to_csv(dataPath+\"results-list.csv\", index=False)\n",
    "    # If the list already exists, add the params used\n",
    "    else:\n",
    "        paramList = pd.read_csv(dataPath+\"results-list.csv\")\n",
    "        frames = [paramList, dfParamsUsed]\n",
    "        paramList = pd.concat(frames)\n",
    "        pd.DataFrame(paramList).to_csv(dataPath+\"results-list.csv\", index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sensitivityClassificationStrat6(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, classifParams, thresholds=False):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resClassificationStrat = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            #print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            if sr < 6:\n",
    "                continue\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            #For 6 classes\n",
    "            d[\"label_strat\"] = 0\n",
    "            d.loc[d[perf] > t * 0.5, \"label_strat\"] = 1\n",
    "            d.loc[d[perf] > t * 0.75, \"label_strat\"] = 2\n",
    "            d.loc[d[perf] > t * 1, \"label_strat\"] = 3\n",
    "            d.loc[d[perf] > t * 1.25, \"label_strat\"] = 4\n",
    "            d.loc[d[perf] > t * 1.5, \"label_strat\"] = 5\n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "\n",
    "            cleanStrat = d.drop([\"perf\"],axis=1,errors=\"ignore\")\n",
    "\n",
    "            c = tree.DecisionTreeClassifier(**classifParams)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for train_index, test_index in shuffle_split.split(cleanStrat,cleanStrat.label_strat):\n",
    "                    c.fit(cleanStrat.drop([\"label\",\"label_strat\"],axis=1).iloc[train_index], cleanStrat.label_strat.iloc[train_index])\n",
    "                    pred = c.predict(cleanStrat.drop([\"label\",\"label_strat\"],axis=1).iloc[test_index])\n",
    "                    \n",
    "                    dfTest = pd.DataFrame()\n",
    "                    dfTest[\"label_strat\"] = cleanStrat.label_strat.iloc[test_index]\n",
    "                    dfTest[\"label\"] = cleanStrat.label.iloc[test_index]\n",
    "                    dfTest[\"pred\"] = pred\n",
    "\n",
    "                    TN += dfTest[(dfTest.label == 0) & (dfTest.pred <= 2)].shape[0]\n",
    "                    TP += dfTest[(dfTest.label == 1) & (dfTest.pred > 2)].shape[0]\n",
    "                    FN += dfTest[(dfTest.label == 1) & (dfTest.pred <= 2)].shape[0]\n",
    "                    FP += dfTest[(dfTest.label == 0) & (dfTest.pred > 2)].shape[0]\n",
    "\n",
    "\n",
    "                resClassificationStrat[\"sr\"].append(sr)\n",
    "                resClassificationStrat[\"t\"].append(t)\n",
    "                resClassificationStrat[\"TN\"].append(TN/NSUBS)\n",
    "                resClassificationStrat[\"TP\"].append(TP/NSUBS)\n",
    "                resClassificationStrat[\"FN\"].append(FN/NSUBS)\n",
    "                resClassificationStrat[\"FP\"].append(FP/NSUBS)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "                break\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    pd.DataFrame(resClassificationStrat).to_csv(newFilename+\"-classification_strat_6.csv\", index=False)\n",
    "    \n",
    "    classifStratParamsUsed = dict(classifParams)\n",
    "    classifStratParamsUsed['file']=filename\n",
    "    classifStratParamsUsed['results']=newFilename+\"-classification_strat_6.csv\"\n",
    "    \n",
    "    dfParamsUsed = pd.DataFrame.from_dict([classifStratParamsUsed])\n",
    "    \n",
    "    # If params list does not exists, create it\n",
    "    if not os.path.exists(dataPath+\"results-list.csv\"):\n",
    "        dfParamsUsed.to_csv(dataPath+\"results-list.csv\", index=False)\n",
    "    # If the list already exists, add the params used\n",
    "    else:\n",
    "        paramList = pd.read_csv(dataPath+\"results-list.csv\")\n",
    "        frames = [paramList, dfParamsUsed]\n",
    "        paramList = pd.concat(frames)\n",
    "        pd.DataFrame(paramList).to_csv(dataPath+\"results-list.csv\", index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sensitivityClassificationStrat8(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, classifParams, thresholds=False):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resClassificationStrat = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            #print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            if sr < 8:\n",
    "                continue\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            #For 8 classes\n",
    "            d[\"label_strat\"] = 0\n",
    "            d.loc[d[perf] > t * 0.25, \"label_strat\"] = 1\n",
    "            d.loc[d[perf] > t * 0.5, \"label_strat\"] = 2\n",
    "            d.loc[d[perf] > t * 0.75, \"label_strat\"] = 3\n",
    "            d.loc[d[perf] > t * 1, \"label_strat\"] = 4\n",
    "            d.loc[d[perf] > t * 1.25, \"label_strat\"] = 5\n",
    "            d.loc[d[perf] > t * 1.5, \"label_strat\"] = 6\n",
    "            d.loc[d[perf] > t * 1.75, \"label_strat\"] = 7\n",
    "            \n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "\n",
    "            cleanStrat = d.drop([\"perf\"],axis=1,errors=\"ignore\")\n",
    "\n",
    "            c = tree.DecisionTreeClassifier(**classifParams)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for train_index, test_index in shuffle_split.split(cleanStrat,cleanStrat.label_strat):\n",
    "                    c.fit(cleanStrat.drop([\"label\",\"label_strat\"],axis=1).iloc[train_index], cleanStrat.label_strat.iloc[train_index])\n",
    "                    pred = c.predict(cleanStrat.drop([\"label\",\"label_strat\"],axis=1).iloc[test_index])\n",
    "                    \n",
    "                    dfTest = pd.DataFrame()\n",
    "                    dfTest[\"label_strat\"] = cleanStrat.label_strat.iloc[test_index]\n",
    "                    dfTest[\"label\"] = cleanStrat.label.iloc[test_index]\n",
    "                    dfTest[\"pred\"] = pred\n",
    "\n",
    "                    TN += dfTest[(dfTest.label == 0) & (dfTest.pred <= 2)].shape[0]\n",
    "                    TP += dfTest[(dfTest.label == 1) & (dfTest.pred > 2)].shape[0]\n",
    "                    FN += dfTest[(dfTest.label == 1) & (dfTest.pred <= 2)].shape[0]\n",
    "                    FP += dfTest[(dfTest.label == 0) & (dfTest.pred > 2)].shape[0]\n",
    "\n",
    "\n",
    "                resClassificationStrat[\"sr\"].append(sr)\n",
    "                resClassificationStrat[\"t\"].append(t)\n",
    "                resClassificationStrat[\"TN\"].append(TN/NSUBS)\n",
    "                resClassificationStrat[\"TP\"].append(TP/NSUBS)\n",
    "                resClassificationStrat[\"FN\"].append(FN/NSUBS)\n",
    "                resClassificationStrat[\"FP\"].append(FP/NSUBS)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "                break\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    pd.DataFrame(resClassificationStrat).to_csv(newFilename+\"-classification_strat_8.csv\", index=False)\n",
    "    \n",
    "    classifStratParamsUsed = dict(classifParams)\n",
    "    classifStratParamsUsed['file']=filename\n",
    "    classifStratParamsUsed['results']=newFilename+\"-classification_strat_8.csv\"\n",
    "    \n",
    "    dfParamsUsed = pd.DataFrame.from_dict([classifStratParamsUsed])\n",
    "    \n",
    "    # If params list does not exists, create it\n",
    "    if not os.path.exists(dataPath+\"results-list.csv\"):\n",
    "        dfParamsUsed.to_csv(dataPath+\"results-list.csv\", index=False)\n",
    "    # If the list already exists, add the params used\n",
    "    else:\n",
    "        paramList = pd.read_csv(dataPath+\"results-list.csv\")\n",
    "        frames = [paramList, dfParamsUsed]\n",
    "        paramList = pd.concat(frames)\n",
    "        pd.DataFrame(paramList).to_csv(dataPath+\"results-list.csv\", index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(datasetPath, dataPath, filename, perf, NBINS,NSUBS, srm, srM, srs, classifParams, regParams):\n",
    "    sensitivityClassification(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM, srs = srs, classifParams=classifParams)\n",
    "    sensitivityRegression(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM, srs = srs, regParams=regParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search to create different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifParams = dict(classParamsDefault)\n",
    "regParams = dict(regParamsDefault)\n",
    "\n",
    "for k,filename in enumerate(filenames):\n",
    "    #for max_depth in [None,10,20,30,40,50,60,70,80,90]:\n",
    "    for max_depth in [None,10,20]:\n",
    "        #for max_leaf_nodes in [10,20,30,40,50,60,70,80,90]:\n",
    "        for max_leaf_nodes in [10,20]:\n",
    "            #for min_samples_leaf in [1,2,4,6,8,10]:\n",
    "            for min_samples_leaf in [1,2]:\n",
    "\n",
    "                classifParams = dict(classParamsDefault)\n",
    "                regParams = dict(regParamsDefault)\n",
    "\n",
    "                classifParams['criterion']=\"entropy\"\n",
    "                classifParams['max_leaf_nodes'] = max_leaf_nodes\n",
    "                classifParams['min_samples_leaf']=min_samples_leaf\n",
    "                classifParams['max_depth']=max_depth\n",
    "\n",
    "                regParams['min_samples_leaf']=min_samples_leaf\n",
    "                regParams['max_leaf_nodes'] = max_leaf_nodes\n",
    "                regParams['max_depth'] = max_depth\n",
    "        \n",
    "                sensitivity(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM[filename], srs = srs[filename], classifParams=classifParams, regParams=regParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use previously created data (here in ./data2) to get the 3 best configurations in order to have a more precise information, but taking longer to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsList = pd.read_csv(\"./dataTest/results-list.csv\")\n",
    "\n",
    "serie = []\n",
    "for i in resultsList['results']:\n",
    "    serie.append(i.split(\"-\")[2].split(\".\")[0])\n",
    "serie = pd.Series(serie)\n",
    "resultsList['type'] = serie\n",
    "\n",
    "accuracy = []\n",
    "for i in resultsList['results']:\n",
    "    dfTemp = pd.read_csv(i)\n",
    "    dfMean = dfTemp.groupby(['sr']).mean().drop(['t'],axis=1)\n",
    "    dfMean['accuracy']= (dfMean['TP']+dfMean['TN']) / (dfMean['TP']+dfMean['TN']+dfMean['FN']+dfMean['FP'])\n",
    "    accuracy.append(dfMean['accuracy'].mean())\n",
    "resultsList['accuracy'] = pd.Series(accuracy)\n",
    "\n",
    "numberOfBestConfig = 3\n",
    "metric = \"accuracy\"\n",
    "\n",
    "configSet = []\n",
    "resultsList2 = resultsList.where(pd.notnull(resultsList), None)\n",
    "for f in resultsList2.file.unique():\n",
    "    for t in resultsList2.type.unique():\n",
    "        for index, r in resultsList2.loc[(resultsList[\"file\"]==f) & (resultsList2[\"type\"]==t)].sort_values(metric, ascending=False)[:numberOfBestConfig].iterrows():\n",
    "            configuration = {}\n",
    "            for i in r.keys():\n",
    "                if not i in [\"results\",\"type\",\"accuracy\",\"file\"]:\n",
    "                    configuration[i] = r[i]\n",
    "            configSet.append({\"file\":r[\"file\"],\"type\":r[\"type\"],\"configuration\":configuration})\n",
    "\n",
    "dfConfig = pd.DataFrame(configSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration    {'class_weight': None, 'criterion': 'entropy',...\n",
      "file                                                        Apache\n",
      "type                                                classification\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dataPath = \"./dataTest2/\"\n",
    "for index, row in dfConfig.iterrows():\n",
    "    if row['type']==\"classification\":\n",
    "        sensitivityClassification(datasetPath = datasetPath, dataPath = dataPath, filename = row['file'], perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM[row['file']], srs = srs[row['file']], classifParams=row['configuration'])\n",
    "    elif row['type']==\"classification_strat_6\":\n",
    "        sensitivityClassificationStrat6(datasetPath = datasetPath, dataPath = dataPath, filename = row['file'], perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM[row['file']], srs = srs[row['file']], classifParams=row['configuration'])\n",
    "    elif row['type']==\"classification_strat_8\":\n",
    "        sensitivityClassificationStrat8(datasetPath = datasetPath, dataPath = dataPath, filename = row['file'], perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM[row['file']], srs = srs[row['file']], classifParams=row['configuration'])\n",
    "    elif row['type']==\"regression\":\n",
    "        del(row['configuration']['class_weight'])\n",
    "        sensitivityRegression(datasetPath = datasetPath, dataPath = dataPath, filename = row['file'], perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM[row['file']], srs = srs[row['file']], regParams=row['configuration'])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
