{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "#Params\n",
    "datasetPath = \"../datasets/\"\n",
    "dataPath = \"./finalData/\"\n",
    "resultPath = \"./finalResults/\"\n",
    "#filenames = [\"Apache\",\"BerkeleyC\",\"BerkeleyJ\",\"LLVM\",\"SQLite\",\"Dune\",\"HIPAcc\",\"HSMGP\",\"JavaGC\"]\n",
    "filenames = [\"JavaGC\"]\n",
    "perf=\"perf\"\n",
    "\n",
    "\n",
    "#Params for sensistivity\n",
    "NBINS = 50 # Number of vertical bins for threshold\n",
    "NSUBS = 10 # Number of training sets to average on\n",
    "srm = 1 # Minimum sampling size\n",
    "srM={}\n",
    "srs = {}\n",
    "for filename in filenames:\n",
    "    srM[filename] = int(subprocess.check_output(\"echo $(wc -l < \"+datasetPath+filename+\".csv)\", shell=True)) # Maximum sampling size\n",
    "    srs[filename] = srM[filename]//100 # Sampling step between two iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def newVersionFilename(path, filename):\n",
    "    # Get all the files in the {path} directory starting with {filename}\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f)) and f.startswith(filename+\"-\")]\n",
    "    files.sort(reverse=True)\n",
    "    # If no file yet\n",
    "    if len(files)==0:\n",
    "        return path+filename+\"-\"+str(1).zfill(4)\n",
    "    # Split the last one\n",
    "    splitted = files[0].split(\"-\")\n",
    "    # Get the last version\n",
    "    num = int(splitted[len(splitted)-2].split(\".\")[0])\n",
    "    # Return the full name with new version\n",
    "    return path+filename+\"-\"+str(num+1).zfill(4)\n",
    "\n",
    "\n",
    "def sensitivityClassification(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resClassification = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "\n",
    "            clean = d.drop([\"perf\"],axis=1,errors=\"ignore\")\n",
    "\n",
    "            c = tree.DecisionTreeClassifier()\n",
    "\n",
    "            try:\n",
    "\n",
    "                for train_index, test_index in shuffle_split.split(clean,clean.label):\n",
    "                    c.fit(clean.drop([\"label\"],axis=1).iloc[train_index], clean.label.iloc[train_index])\n",
    "                    pred = c.predict(clean.drop([\"label\"],axis=1).iloc[test_index])\n",
    "                    \n",
    "                    dfTest = pd.DataFrame()\n",
    "                    dfTest[\"label\"] = clean.label.iloc[test_index]\n",
    "                    dfTest[\"pred\"] = pred\n",
    "\n",
    "                    TN += dfTest[(dfTest.label == 0) & (dfTest.pred == 0)].shape[0]\n",
    "                    TP += dfTest[(dfTest.label == 1) & (dfTest.pred == 1)].shape[0]\n",
    "                    FN += dfTest[(dfTest.label == 1) & (dfTest.pred == 0)].shape[0]\n",
    "                    FP += dfTest[(dfTest.label == 0) & (dfTest.pred == 1)].shape[0]\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "                break\n",
    "\n",
    "            resClassification[\"sr\"].append(sr)\n",
    "            resClassification[\"t\"].append(t)\n",
    "            resClassification[\"TN\"].append(TN/NSUBS)\n",
    "            resClassification[\"TP\"].append(TP/NSUBS)\n",
    "            resClassification[\"FN\"].append(FN/NSUBS)\n",
    "            resClassification[\"FP\"].append(FP/NSUBS)\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    \n",
    "    pd.DataFrame(resClassification).to_csv(newFilename+\"-classification.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityRegression(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs):\n",
    "\n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "\n",
    "    resRegression = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[],\"MSE\":[]}\n",
    "\n",
    "    #for sr in range(1,99):\n",
    "    for sr in range(srm+1,int(0.9*srM),srs):\n",
    "        for t in thresholds:\n",
    "            #print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            \n",
    "            shuffle_split = StratifiedShuffleSplit(train_size=sr, n_splits=NSUBS)\n",
    "            \n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1\n",
    "            \n",
    "            \n",
    "            TN = TP = FN = FP = MSE = 0 # Counters for regression results\n",
    "\n",
    "            c = tree.DecisionTreeRegressor()\n",
    "\n",
    "            for train_index, test_index in shuffle_split.split(d,d.label):\n",
    "                c.fit(d.drop([perf,\"label\"],axis=1).iloc[train_index], d[perf].iloc[train_index])\n",
    "                pred = c.predict(d.drop([perf,\"label\"],axis=1).iloc[test_index])\n",
    "                #print(list(pred))\n",
    "                #print(list(clean.label.iloc[test_index]))\n",
    "                #print()\n",
    "                dfTest = pd.DataFrame()\n",
    "                dfTest[perf] = d[perf].iloc[test_index]\n",
    "                dfTest[\"pred\"] = pred\n",
    "                dfTest[\"label\"] = d.label.iloc[test_index]\n",
    "                dfTest[\"label_pred\"] = 0\n",
    "                dfTest.loc[dfTest[\"pred\"] > t, \"label_pred\"] = 1\n",
    "                                 \n",
    "                MSE = mse(dfTest[perf],dfTest[\"pred\"])\n",
    "\n",
    "                TN += dfTest[(dfTest.label == 0) & (dfTest.label_pred == 0)].shape[0]\n",
    "                TP += dfTest[(dfTest.label == 1) & (dfTest.label_pred == 1)].shape[0]\n",
    "                FN += dfTest[(dfTest.label == 1) & (dfTest.label_pred == 0)].shape[0]\n",
    "                FP += dfTest[(dfTest.label == 0) & (dfTest.label_pred == 1)].shape[0]\n",
    "\n",
    "            resRegression[\"sr\"].append(sr)\n",
    "            resRegression[\"t\"].append(t)\n",
    "            resRegression[\"MSE\"].append(MSE/NSUBS)\n",
    "            resRegression[\"TN\"].append(TN/NSUBS)\n",
    "            resRegression[\"TP\"].append(TP/NSUBS)\n",
    "            resRegression[\"FN\"].append(FN/NSUBS)\n",
    "            resRegression[\"FP\"].append(FP/NSUBS)\n",
    "            \n",
    "            #break\n",
    "        #break\n",
    "        \n",
    "    newFilename = newVersionFilename(dataPath,filename)\n",
    "    pd.DataFrame(resRegression).to_csv(newFilename+\"-regression.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(datasetPath, dataPath, filename, perf, NBINS,NSUBS, srm, srM, srs):\n",
    "    sensitivityClassification(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)\n",
    "    sensitivityRegression(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                    NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cfbbe6687de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     sensitivity(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n\u001b[0;32m----> 3\u001b[0;31m                         NSUBS = NSUBS, srm = srm, srM = srM[filename], srs = srs[filename])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-9eb38ce85655>\u001b[0m in \u001b[0;36msensitivity\u001b[0;34m(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs)\u001b[0m\n\u001b[1;32m      3\u001b[0m                     NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)\n\u001b[1;32m      4\u001b[0m     sensitivityRegression(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n\u001b[0;32m----> 5\u001b[0;31m                     NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e42e73e3cb8a>\u001b[0m in \u001b[0;36msensitivityRegression\u001b[0;34m(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshuffle_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m#print(list(pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k,filename in enumerate(filenames):\n",
    "    sensitivity(datasetPath = datasetPath, dataPath = dataPath, filename = filename, perf = perf, NBINS = NBINS,\n",
    "                        NSUBS = NSUBS, srm = srm, srM = srM[filename], srs = srs[filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
